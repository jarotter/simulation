---
title: "Tarea 3"
author: "Sergio Arnaud, Jorge Rotter"
date: "10/11/2018"
output: 
  pdf_document:
    latex_engine: lualatex
  html_document: default
header-includes:
- \usepackage{amsmath}
- \usepackage{mdsymbol}
---
```{r echo=F, warning=F, message=F}
library(MASS)
library(tidyverse)
library(qqplotr)
library(tictoc)
```

## Pregunta 1
Un estadístico está interesado en el número N de peces en un estanque. El captura 250 peces, los marca y los regresa al estanque. Unos cuantos días después regresa y atrapa peces hasta que obtiene 50 peces marcados, en ese punto también tiene 124 peces no marcados (la muestra total es de 174 peces).

  - ¿Cuál es la estimación de N?
  
$\frac{124}{50} = 2.48$ de forma que la estimación de N está dada por $2.48\cdot250=620$
  
  - Hagan un programa (en excel o en R), que permita simular el proceso de obtener la primera y segunda muestra considerando como parámetros el tamaño N de la población de interés, el tamaño de la primera y segunda muestra y como datos a estimar son: de qué tamaño debe ser n1 y n2 para obtener una buena aproximación y ver cómo se afecta por el tamaño N.

El siguiente código, para una N dada (en este caso N=620) regresa los tamaños de muestra (n1 y n2) que dan la mejor estimación de N donde n1 es la muestra que se debe de obtener y marcar en una primera instancia y n2 es la muestra que se debe obtener en una segunda instancia para comparar los marcados vs los no marcados y estimar la población total.
```{r}
N <- 620
j <-1
means <-matrix(0, nrow=round(N/4), ncol=round(N/4))
for (N1 in 1:round(N/4)){
  for (N2 in 1:round(N/4)){
    aprox = rep(0,15)
    for (i in 1:15){
       l = c(rep(0,N1),rep(1,N-N1))
       s <- sample(l,N2)
       aprox[i] = (sum(s)/(length(s)-sum(s)))*N1
    }
    means[[N1,N2]] = mean(aprox)
    j = j+1
  }
}
ans <- which((abs(means - N)) == min(abs(means - N)),arr.ind=T)
# n1
ans[1]
# n2
ans[2]
```


## Pregunta 2

Este problema es una versión simplificada de dos problemas comunes que enfretan las compañías de seguros: calcular la 
probabilidad de quebrar y estimar cuánto dinero podrán hacer.
Supongan que una compañía tiene activos (todo en dólares) por $\$10^6$ y $n=1,000$ clientes que pagan individualmente una prima
anual de $5,500 al principio de cada año. Basándose en experiencia previa, se estima que la probabilidad de que un cliente haga
reclamo es $p=0.1$ por año, independientemente de reclamos previos de otros clientes. El tamaño $X$ de los reclamos varía, y
tiene la siguiente densidad con $\alpha = 5$ y $\beta = 125,000$
\[
f(x) = I(x\geq0)\frac{\alpha \beta^\alpha}{(x+\beta)^{\alpha+1}}
\]

Consideremos la fortuna de la compañía en un horizonte de cinco años, y sea $Z(t)$ la cantidad de activo al terminar el año $t$,
de manera que $Z(0)=1,000,000$ y $Z(t)=I(Z(t-1)>0)\max\{Z(t-1)+\textrm{primas}-\textrm{reclamos},0\}$

a. Calcule la función de distribución $F_X$, $\mathbb{E}[X]$y $\textrm{Var}(X)$. Obtenga por simulación una muestra de $X$, calcule
su distribución empírica y compare con la verdadera.

\[
\begin{align}
F_X(x) &= \int_0^x \frac{\alpha \beta^\alpha}{(t+\beta)^{\alpha+1}}dt \\
&= \int_\beta^{x+\beta}\alpha \beta^\alpha u^{-(\alpha+1)} du\\
&= -\beta^\alpha \left[ \frac{1}{u^\alpha} \right]^{x+\beta}_\beta \\ 
&= 1 - \left(1+\frac{\beta}{x+\beta} \right)^\alpha
\end{align}
\]

Para la esperanza y varianza, notemos que
\[
\begin{align}
\mathbb{E}[(X + \beta)^k] &= \int_0^\infty\frac{(x+b)^k\alpha\beta^\alpha}{(x+\beta)^{\alpha+1}} \\
&= \int_0^\infty \frac{\alpha \beta^\alpha}{(\beta+x)^{\alpha + 1 - k}} dx \\
&= \int_0^\infty\frac{\alpha \beta^k}{\alpha-k} \frac{(\alpha-k) \beta^{\alpha-k}}{(\beta+x)^{\alpha-k+1}} dx \\
&= \frac{\alpha \beta^k}{\alpha-k} \int_0^\infty f_Y(x) dx \\
&=\frac{\alpha \beta^k}{\alpha-k}
\end{align}
\]

Donde $Y~Pareto(\alpha-k, \beta)$ (la misma familia que $X$).

Luego,

\[
\begin{align}
\mathbb{E}[X] &=  \mathbb{E}[X+\beta]-\beta \\
&= \frac{\alpha\beta}{\alpha-1} - \beta  \\
&= \frac{\beta}{\alpha-1}
\end{align}
\]

\[
\begin{align}
\mathrm{Var}(X) &= \mathbb{E}[X^2]-\mathbb{E}[X]^2 \\
&=  \mathbb{E}[(X+\beta)^2] - 2\beta\mathbb{E}[X] - \beta^2 - \mathbb{E}[X]^2 \\ 
&=\frac{\alpha \beta^2}{\alpha-2} - \frac{2\beta^2}{\alpha-1} - \beta^2 -\left( \frac{\beta}{\alpha-1}\right)^2 \\ 
&= \frac{\alpha \beta^2}{(\alpha-1)^2(\alpha-2)}
\end{align}
\]

Y para muestrear, usamos el método de la transformación inversa
\[
\begin{align}
y=1-\left( \frac{\beta}{x+\beta} \right)^\alpha &\Leftrightarrow 1-y=\left( \frac{\beta}{x+\beta} \right)^\alpha \\
&\Leftrightarrow (1-y)^{\frac{1}{\alpha}} = \frac{\beta}{x+\beta} \\
&\Leftrightarrow \beta (1-y)^{-\frac{1}{\alpha}} - \beta = x
\end{align}
\]

```{r}
qpareto <- function(x, alpha, beta){
  beta*((1-x)^(-1/alpha) - 1)
}

ppareto <- function(x, alpha, beta){
  1-(1+x/beta)^(-alpha)
}

rpareto <- function(n, alpha, beta){
  u <- runif(n)
  qpareto(u, alpha, beta)
}

x_sample <- data_frame(simulado=rpareto(1000,5, 125000))
  
ggplot() +
  stat_ecdf(data=x_sample, 
            mapping=aes(x=simulado, colour='simulado'), 
            geom='step', 
            pad = F) +
  stat_function(data=data_frame(mx=c(0,max(x_sample$simulado))),
                mapping=aes(colour='teórico'),
                fun=function(x) ppareto(x,5,125000))+
  labs(x='x', y='F(x)')


ks.test(x_sample$simulado, 'ppareto', alpha=5, beta=125000)
rm(x_sample)
```

La prueba no da evidencia para rechazar la hipótesis nula, y en la gráfica sí se ven similares ambas distribuciones. 

Escriba una función para simular los activos de la compañía por cinco años

```{r}
activos <- function(activo_inicial, n_clientes, prima, p, horizonte, alpha, beta){

  z <- rep(0,horizonte+1)
  z[1] <- activo_inicial

  for(i in 2:(horizonte+1)){

    if(z[i-1] <= 0) break

    reclamos <- rbernoulli(n_clientes, p)
    montos <- rpareto(n_clientes, alpha, beta)*reclamos
    z[i] <- max(z[i-1]+n_clientes*prima-sum(montos), 0)
  }
  
  z
}

activos_n<- function(n, n_clientes=1000, 
                     activo_inicial=1e6, prima=5500, p=0.1,
                     alpha=5, beta=125000, 
                     horizonte=5){
  replicate(n, activos(activo_inicial, n_clientes, prima, p, horizonte, alpha, beta)) %>%
    t()
}

```

Estime la probabilidad de que la compañía se vaya a bancarrota

```{r}
mean(activos_n(10000)[,6]==0)
```

Y la ganancia esperada
```{r}
mean(activos_n(10000)[,6])
```

Suponga ahora que la compañía toma ganancias. Repita las preguntas anteriores.
```{r}
activos_gan <- function(activo_inicial, n_clientes, prima, p, horizonte, alpha, beta){

  z <- rep(0,horizonte+1)
  ganancias <- 0
  z[1] <- activo_inicial

  for(i in 2:(horizonte+1)){

    if(z[i-1] <= 0) break

    reclamos <- rbernoulli(n_clientes, p)
    montos <- rpareto(n_clientes, alpha, beta)*reclamos

    z[i] <- z[i-1] + n_clientes*prima - sum(montos)
    
    if(z[i] > activo_inicial){
      ganancias <- ganancias + z[i] - activo_inicial
      z[i] <- activo_inicial
    }
  }
  
  z
}

activos_gan_n<- function(n, n_clientes=1000, 
                     activo_inicial=1e6, prima=5500, p=0.1,
                     alpha=5, beta=125000, 
                     horizonte=5){
  replicate(n, activos_gan(activo_inicial, n_clientes, prima, p, horizonte, alpha, beta)) %>%
    t()
}

nueva_forma <- activos_gan_n(1000)

mean(nueva_forma[,6])
mean(nueva_forma[,6]==0)

```

## Pregunta 3

Las densidades dadas son:
```{r}
cauchy <- function(x, beta, gamma){ 
  1 / (pi*beta*(1 + ((x-gamma)/beta)^2))
}
gumbel <- function(x, beta, gamma){ 
  (1 / beta) *exp(-exp(-(x-gamma)/beta) - (x-gamma)/beta)
}
logistic <- function(x, beta, gamma){
  ( (1/beta)*exp(-(x-gamma)/beta) ) / ((1 + exp(-(x)))^2)
}
pareto <- function(x, c, alpha){
  alpha*((c^alpha))/(x^(alpha+1))
}

```

#### Cauchy
Para generar la muestra aleatoria de la distribución Cauchy podemos usar el teorema de la transformada inversa y obtenemos la siguiente función:

```{r}
rcauchy_ <- function(n, beta, gamma){
  u <- runif(n)
  cauchy_sample <- tan(pi*(u-1/2))*beta + gamma
  return (cauchy_sample)
}
```

Probando el método

```{r}
beta <- 1
gamma <- 0
n <- 5000
cauchy_sample = rcauchy_(n, beta, gamma)
hist(cauchy_sample, xlim =c(-10,10), breaks = c(min(cauchy_sample),seq(from=-10,to=10,by=.25), max(cauchy_sample)), prob = T)
curve(cauchy(x,beta,gamma),from=-25,to=25,col="blue", add = T)
```

La muestra generada efectivamente sigue una distribución Cauchy.

Verificando empíricamente la ley fuerte de los grandes números:
```{r}
n_values = seq(from=50, to=5000, by=50)
x_barras = rep(0,length(n_values))
for (n in n_values){
  x_barras[n/50] = sum(rcauchy_(n, beta, gamma))/n
}
plot(x_barras)
```
Los valores oscilan alrededor del cero pero hay algunos valores que difieren mucho, esto es normal puesto que la distribución Cauchy no tiene media.

#### Gumbel

Dado que la función de distribución es $e^{-e^{-\frac{x-\gamma}{\beta}}}$, 
invirtiendo tendremos $X = -\beta \log(-\log(u)) + \gamma$, usando el teorema de la
transformación inversa:

```{r}
rgumbel_ <- function(n,beta, gamma){
  u <- runif(n)
  gumbel_sample <- -beta*log(-log(u)) + gamma
  return (gumbel_sample)
}
```
Probando el método

```{r}
gumbel_sample = rgumbel_(5000,beta,gamma)
hist(gumbel_sample, breaks = 50, prob = T)
curve(gumbel(x,beta,gamma),from=-10,to=10,col="red", add=T)
```
La muestra generada efectivamente sigue una distribución Gumbel.

Verificando empíricamente la ley fuerte de los grandes números:
```{r}
x_barras = rep(0,length(n_values))
for (n in n_values){
  x_barras[n/50] = sum(rgumbel_(n, beta, gamma))/n
}
plot(x_barras)
abline(h=(gamma + beta*0.5772), col='red')
```
La media teórica es $\gamma + \beta*c$ donde $c$ es la constante de  Euler–Mascheroni, en la gráfica notamos que, efectivamente, se cumple empíricamente la Ley fuerte de los grandes números.

#### Logística

Dado que la función de distribución es $\frac{1}{1+e^{-(x-\gamma)/\beta}}$, 
invirtiendo tendremos $X = -\beta \log(\frac{1}{u} -1) + \gamma$, usando el teorema de la transformación inversa:

```{r}
rlogistic_ <- function(n,beta,gamma){
  u <- runif(n)
  logistic_sample <- -beta*log(1/u -1) + gamma
  return (logistic_sample)
}
```
Probando el método

```{r}
logistic_sample = rlogistic_(5000,beta,gamma)
hist(logistic_sample, breaks = 50, prob = T)
curve(logistic(x,beta,gamma),from=-10,to=10,col="red", add=T)
```
La muestra generada efectivamente sigue una distribución Logística

Verificando empíricamente la ley fuerte de los grandes números:
```{r}
x_barras = rep(0,length(n_values))
for (n in n_values){
  x_barras[n/50] = sum(rlogistic_(n, beta, gamma))/n
}
plot(x_barras)
abline(h=gamma,col="red")
```
La media teórica es $\gamma$. En la gráfica notamos que, efectivamente, se cumple empíricamente la Ley fuerte de los grandes números.


#### Pareto

La inversa de la función de distribución está dada por $X = \frac{c}{u^{1/\alpha}}$, usando el teorema de la transformada inversa:

```{r}
rpareto_ <- function(n,c,alpha){
  u <- runif(n)
  pareto_sample <- c / (u^(1/alpha))
}
```
Probando el método

```{r}
c <- 1
alpha <- 2
pareto_sample = rpareto_(5000,c,alpha)
hist(pareto_sample, xlim=c(1,5), breaks = c(seq(from=-10,to=10,by=.25),max(pareto_sample)), prob = T)
curve(pareto(x,c,alpha),from=1,to=5,col="blue", add = T)
```
La muestra generada efectivamente sigue una distribución Pareto.

Verificando empíricamente la ley fuerte de los grandes números:
```{r}
x_barras = rep(0,length(n_values))
for (n in n_values){
  x_barras[n/50] = sum(rpareto_(n, c, alpha))/n
}
plot(x_barras)
abline(h=2,col="red")
```
La media teórica es $\frac{c \ \alpha}{\alpha -1} = 2 $. En la gráfica notamos que, efectivamente, se cumple empíricamente la Ley fuerte de los grandes números.

### Pregunta 3

Grafique las densidades indicadas, y dé algoritmos de transformación inversa, composición y aceptación-rechazo para cada una de ellas.

a. 
\[
f(x) = \frac{3x^2}{2} \mathcal{I}_{[-1,1]}(x)
\]
```{r}
ggplot(data.frame(x=c(-1.2,1.2)), aes(x)) +
  stat_function(fun = function(x) ifelse(x>= -1 & x <= 1, 3/2*x^2, 0)) +
  labs(x='x', y='f(x)')
```

Y $F(x) = \int_{-1}^x \frac{3t^2}{2} dt = \frac{1}{2}(x^3+1)$, por lo que la función cuantil es
$F^{-1}(x) = \sqrt[3]{2x^3-1}$.

El método de aceptación-rechazo sería generar parejas $(u,v)$, donde $u \sim \textrm{Unif}(-1,1)$ y $v \sim \textrm{Unif}(0,1.5)$, y nos quedamos con aquellos puntos que satisfacen $v \leq f(u)$. Notemos que la tasa de aceptación es 1/3.

b. 
\[
g(x) = 
\begin{cases}
0, x\leq 0 \\
\frac{x}{a(1-a)}, 0 < x \leq a \\
\frac{1}{1-a}, a < x \leq 1-a \\
\frac{1-x}{a(1-a)}, 1-a < x \leq 1
0, x  > 1
\end{cases}
\]

```{r}
g <- function(a, x){
  ifelse(x<=0, 0,
         ifelse(x <= a, x/(a*(1-a)), 
                ifelse(x <= 1-a, 1/(1-a), 
                       ifelse(x<= 1, (1-x)/(a*(1-a)),0))))
}

ggplot(data.frame(x=c(0,1)), aes(x)) +
  stat_function(fun = function(x) g(1/3, x)) + 
  labs(y='g(x)', x='x')
```

En este caso, la tasa de aceptación para el algoritmo de aceptación-rechazo es 2/3, mejor que arriba.

Para transformación inversa, la función de distribución es
\[
G(x) = 
\begin{cases}
0, x \leq 0 \\
\frac{a^2-x^2}{2(a-1)a}, 0 < x \leq a\\
\frac{a-x}{a-1}, a < x \leq 1-a \\
\frac{(x-1)^2-a^2}{2(a-1)a}, 1-a < x \leq 1 \\
0, x > 1
\end{cases}
\]

## Pregunta 5

Considerando la transformación polar de Marsaglia para generar muestras de normales estándar, muestren que la probabilidad de aceptación de $S = V12 + V22$ en el paso 2 es $\pi/4$, y encuentren la distribución del número de rechazos de S antes de que ocurra una aceptación. ¿Cuál es el número esperado de ejecuciones del paso 1?

Se tienen $V_1, V_2 \sim Unif(-1,1)$ y $S=V_1^2 + V_2^2$ si $V_1^2 + V_2^2 > 1$. Por un lado, el area de aceptación es un circulo de radio 1 y centrado en cero. Por otro lado el area total es el recuadro $[-1,1]  \times [-1,1]$, el área del círculo es $\pi$ y el area del recuadro es igual a dos por lo que la probabilidad de aceptación es $\frac{\pi}{4}$

El número de rechazos de S antes de que ocurra una aceptación se distribuye como una geométrica con parámetro $\frac{\pi}{4}$.

Si $X \sim Geom(\frac{\pi}{4})$, entonces eel número esperado de ejecuciones del paso 1 es igual a la esperanza X, $E[X] = \frac{1}{\frac{\pi}{4}} = \frac{4}{pi}$

Que tiene función cuantil más o menos fea por la inversión de cosas no biyectivas, por lo que mejor podríamos usar el método de aceptación-rechazo.

## Pregunta 6

Obtenga 1000 números de la distribución 
\[
p(x) = \frac{2x}{k(k+1)}, x\in\{1, \cdots, k\}
\]
para $k = 100$.

```{r}
construir_tabla <- function(k){
  x <- 1:k
  2*x/(k*k+1)
}

rp <- function(n, k){
  pk <- 2*1:k/(k*(k+1))
  sample(1:k, n, replace = T, prob=pk)
}

rp(1000,10)
```

## Pregunta 7

Desarrollen un algoritmo para generar una variable aleatoria binomial, usando la técnica de convolución (Hint: ¿cuál es la relación entre binomiales y Bernoullis?) Generar una muestra de 100,000 números. ¿Qué método es más eficiente, el de con- voluciones o la función rbinom en R?

Podemos usar el método de la convolución para generar la muestra aleatoria de una Binomial usando el hecho de que si $X_i \sim Ber(p) \quad i\in\{1,...,n\}$ entonces $\sum_{i=1}^n Xi \sim Bin(n,p)$.

La siguiente función utiliza dicha información para generar la muestra aleatoria de tamaño n de una variable aleatoria binomial de parámetros n,p:
```{r}
rbinom_ <-function(n,size,p){
  binomial_sample <- rep(0,n)
  for (i in 1:n){
    binomial_sample[i] <- sum(sample(0:1, size=size,replace=T, prob=c(1-p,p)))
  }
  return(binomial_sample)
}
```
Finalmente, comparemos los tiempos de ejecución para ver cual es más eficiente:

```{r}
system.time(rbinom_(1000,10,.5))
system.time(rbinom(1000,10,.5))
```
Como era de esperarse, la función de R es más eficiente. El algoritmo utilizado por R es llamado el algoritmo BTPEC para samplear normales (Kachitvichyanukul, V. and Schmeiser, B. W. (1988). Binomial random variate generation.)


## Pregunta 8
Para un proceso Poisson no homogéneo con función de intensidad dada por

\[
\lambda(t)= 
\begin{cases}
5, t\in(1,2],(3,4], \cdots \\
3, t \in (0,1], (2,3], \cdots 
\end{cases}
\]

Grafique un ejemplo del proceso, considerando en intervalo de tiempo $[0,100]$
```{r}

# Generar primeros N eventos
poisson_nh <- function(lambda, cota, N=0, Tmax=Inf, by_time=T){
  t_inter <- 0
  t_actual <- 0
  tiempo_evento <- integer()
  n <- 0
  
  while((by_time & t_actual<Tmax) | (!by_time & n<N)){
    t_inter <- rexp(1, cota)
    t_actual <- t_actual + t_inter
    if(runif(1) < lambda(t_actual)/cota){
      n <- n+1
      if(t_actual<Tmax)
        tiempo_evento <- c(tiempo_evento, t_actual)
    }
  }
  
  tiempo_evento
}


lambda <- function(t){
  ifelse(floor(t)%%2==1, 5, 3)
}

poisson_plot<- function(t){
  data_frame(ns=1:length(t),
           tiempo=t) %>%
  ggplot(aes(x=t, y=ns)) +
  geom_step() +
  labs(x='t', y='N(t)')
}

poisson_nh(lambda, 5, Tmax=100) %>%
  poisson_plot()

```

Grafique el proceso hasta obtener 100 eventos
```{r}
poisson_nh(lambda, 5, N=100, by_time=F) %>%
  poisson_plot()
```

Estime la probabilidad de que el número de eventos observados en el periodo de tiempo (1.25,3] sea mayor a dos.

```{r}
count_obs <- function(t, lb){

  if(length(which(t<lb))==0)
    0
  else
    length(t) - max(which(t<lb))
}

replicate(10000, poisson_nh(lambda, 5, Tmax=3)) %>%
  map_dbl(count_obs, 1.25) %>%
  map_lgl(function(x) x > 2) %>%
  mean() %>%
  print()
```

## Pregunta 9

Simular un proceso Poisson no homogéneo con función de intensidad dada por
$\lambda(t) = sen(t)$.

La siguiente función genera el proceso:
```{r}
non_homogeneous_poisson_process <- function(t){
  # lambda = 1 acota la función de intensidad del proceso
  lambda <- 1

  s = c(rexp(1,1))
  while(tail(s,1) < t){
    s = c(s, tail(s,1)+rexp(1,1))
  }
  s = s[-length(s)]
  
  u <- runif(length(s))
  ss <- s[u <= abs(sin(s)/lambda)]
  Ns <- 1:length(ss)
  
  return(list(intentados=s, aceptados = ss, cuenta= Ns))
}
```

Simulando el proceso.
```{r}
ans = non_homogeneous_poisson_process(50)
par(mfrow=c(1,2), pty='s')
plot(ans$aceptados, ans$cuenta, type = "s", ylab = "N(t)",xlab='t',
     main = "Proceso Poisson no homogéneo",
     sub = expression(lambda(t) == exp(paste("sen","(t)")))) 

plot(ans$intentados, sin(ans$intentados),col = "red", lwd = 1 )
points(ans$aceptados, sin(ans$aceptados),col = "blue", lwd = 1)
curve(sin(x), from=0, to=100, add=T)
abline(h=-.5)
abline(h=.5)
```
La gráfica de la izquierda es el proceso simulado, la  gráfica de la derecha es la gráfica de sen(t), los puntos sobre la curva son aquellos puntos de la forma $(t,sen(t))$, los puntos rojos fueron rechazados, en caso contrario fueron aceptados en el proceso.


## Pregunta 10

Una compañía de seguros tiene 1000 asegurados, cada uno de los cuales presentará de manera independiente una reclamación en el siguiente mes con probabilidad $p=0.09245$. Suponiendo que las cantidades de los reclamos hechos son variables aleatorias $\mathcal{N}(7000, 25000000)$, estime la probabilidad de que la suma de los reclamos exceda $500,000.

```{r}

simular_mes <- function(n_clientes=1000, p=0.09245, mu=7000, sigma=5000){
  reclamacion <- rbernoulli(n_clientes, p)
  monto <- rnorm(n_clientes, mu, sigma) * reclamacion
  sum(monto)
}

replicate(10000, simular_mes()) %>%
  map_lgl(function(x) x>500000) %>%
  mean()
```

## Pregunta 11

Escribir una función para generar una mezcla de una distribución normal multivariada con dos componentes con medias $\mu_1$ y $\mu_2$ y matrices de covarianzas $S_1$ y $S_2$ respectivamente.

```{r}
mixed_normal <- function(n, mu_1, mu_2, S1, S2,p){
  
  m <- matrix(rnorm(n),nrow = length(mu_1),ncol =n)
  mixed_normals <- matrix(0, nrow=length(mu_1), ncol = n)
  
  B1 <- chol(S1)
  B2 <- chol(S2)
  
  for( i in 1:n){
    if (runif(1) < p){
      mixed_normals[,i] <- mu_1 + B1%*%m[,i]
    }
    else{
      mixed_normals[,i] <-mu_2 + B2%*%m[,i]
    }
  }
  
  return (mixed_normals)
}

```

Con el programa, generar una muestra de tamaño $n = 1000$ observaciones de una mezcla 50% de una normal 4 dimensional con $\mu_1 =(0,0,0,0)$ y $\mu_2 = (2, 3, 4, 5)$, y matrices de covarianzas $S_1 = S_2 = I_4$.
```{r}
normal_multivariate <- mixed_normal(10000,c(2,3,4,5),c(0,0,0,0),diag(4),diag(4),.5 )
```
Obtener los histogramas de las 4 distribuciones marginales.
```{r}
par(mfrow=c(2,2))
for (i in 1:4){
  hist(normal_multivariate[i,],breaks=50)
}
```


### Pregunta 12: Distribución de Wishart
Suponga que $M=X'X$, donde $X$ es una matriz de $n \times d$ de una muestra aleatoria de una distribución $\mathcal{N}_d(\mathbf{0}, \Sigma)$. Entonces $M \sim W_d(\Sigma, n)$. Notemos que en particular $W_1(\sigma ^2, n) \sim \sigma ^2 \chi^2_{(n)}$.

Una forma de generar observaciones de una distribución Wishart es generar muestras de normales con la definición de arriba, pero notamos que el método es muy cososo. Uno más eficiente se basa en la descomposición ed Bartlett: sea $T=(t_{ij})$ una matriz triangular inferior de $d \times d$ con entradas independientes que satisfacen

a) $t_{ij} \sim \mathcal{N}(0,1)$ independientes para $i>j$
b) $t_{ii} \sim \sqrt{\chi^2_{(n-i+1)}}$ para $i\in \{1, \cdots d\}$

Entonces, la matriz $A=T'T$ es Wishart $W_d(\mathbb{I}_n, d)$. Para terminar, si $\Sigma = LL'$ es la descomposición de Cholesky de $\Sigma$, entonces $LAL' \sim W_d(\Sigma, d)$.

Compare el tiempo de ejecución de ambos métodos.

```{r}
sg <- matrix(c(2,-1,0,-1,2,-1,0,-1,2), nrow=3)

rwishart_norm <- function(df=1000, Sigma){
  X <- mvrnorm(df, rep(0, dim(Sigma)[1]), Sigma)
  M <- t(X) %*% X
}

rwishart_norm_n <- function(n, df=1000, Sigma){
  replicate(n, rwishart_norm(df, Sigma), simplify = F)
}

tic('Método por normales')
muestra_normal <- rwishart_norm_n(1000,1000,sg)
toc()

rwishart_choleksy <- function(df=1000, d){
  
  tr_part <- 0:(d-1) %>%
    map(function(i) c(rnorm(i), rep(0, d-i))) %>%
    unlist() %>%
    matrix(nrow=3, ncol=3, byrow=TRUE)
  
  diag_part <- 1:d %>%
    map(function(i) sqrt(rchisq(1, df-i+1))) %>%
    unlist()
  diag_part <- diag_part * diag(d)
  
  A <- (tr_part+diag_part) %*% t(tr_part+diag_part)
  
  
}

rwishart_cholesky_n <- function(n, df=1000, Sigma){
  d <- dim(Sigma)[1]
  L <- t(chol(Sigma))
  replicate(n, rwishart_choleksy(df, d), simplify=FALSE) %>%
    map(function(A) L %*% A %*% t(L))
}

tic('Método de Bartlett')
muestra_cholesky <- rwishart_cholesky_n(n=1000,Sigma=sg)
toc()
```

En mi implementación es más rápido el método por normales, cosa que le atribuyo a la vectorización que microoptimiza la ejecución en `R`. 

### Pregunta 13

Las ocurrencias de huracanes que tocan tierra durante el fenómeno meteorológico “el Niño” se modelan como un proceso Poisson (ver Bove et al (1998)). Los autores aseguran que “Durante un año de ’El Niño’, la probabilidad de dos o más huracanes haciendo contacto con tierra en los estados Unidos es 28 %”. Encontrar la tasa del proceso Poisson.

Si $X \sim Po(\lambda)$, entonces $f(x;\lambda) = \frac{e^{-\lambda}\lambda^x}{x!}$.

Dado que $P(X \geq 2) = .72$ tenemos que $P(X \leq 1) = .28$ pero $P(X \leq 1) = e^{-\lambda} +e^{-\lambda}\lambda = .72$ y resolviendo para $\lambda$ obtenemos: $\lambda = 1.043$

De forma que la tasa del proceso buscado es $\lambda = 1.043$

## Pregunta 14
Comenzando a medio día, comensales llegan a un restaurante de acuerdo a un proceso poisson con tasa de 5 clientes por minuto. El tiempo que cada cliente pasa comiendo es exponencial con media 40, y todos son independientes entre sí y de los tiempos de arribo. Encuentre la distribución, media y varianza del número de comensales en el restaurante a las 2:00pm. Simule el restaurante para verificar.

Como los tiempos de consumo son exponenciales, el número de clientes que sale del restaurante también es un proceso Poisson, independiente del de llegada. Luego,

\[
N(t) = N_L(t)-N_S(t) \sim \mathrm{Poisson}(t(5-\frac{1}{40}))
\]

Por lo que $N(120) \sim \mathrm{Poisson}(597)$ que tiene media y varianza 597. Simulando para comparar

```{r}

obtener_muestra <- function(){
  llegadas <- poisson_nh(function(t) 5, 5, Tmax=120)
  salidas <- poisson_nh(function(t) 1/40, 1/40, N=length(llegadas), by_time = F) + llegadas[1]
  if(length(which(salidas<120))==0)
    length(llegadas)
  else
    length(llegadas) - max(which(salidas<120))
}

muestra_restaurante <- replicate(1000, obtener_muestra())

data_frame(sim=muestra_restaurante) %>%
  ggplot(aes(sample=sim)) +
  geom_qq_band(alpha=0.5, distribution='pois', dparams=597) +
  stat_qq_line() +
  stat_qq_point() +
  labs(x = "Theoretical quantiles", y = "simulated values")

probs <- data_frame(muestra_restaurante) %>%
  group_by(muestra_restaurante) %>%
  count() %>%
  right_join(data_frame(muestra_restaurante=1:max(muestra_restaurante))) %>%
  mutate(probs = ifelse(is.na(n), 0, n)) %>%
  pull(probs)

muestra_unique <- table(muestra_restaurante) %>%
  names() %>%
  as.integer() 

p <- dpois(muestra_unique, lambda=597)
p <- p/sum(p)

chisq.test(table(muestra_restaurante), p=p)
```

### Pregunta 15

Construyan un vector de 100 números crecientes y espaciados regularmente entre 0.1 y 20. Llámenlo SIG2 . Ahora construyan otro vector de longitud 21 empezando en −1 y terminando en 1. Llámenlo RHO.
```{r}
sig2 = seq(from=.1,to=20,length.out=100)
rho = seq(from=-1,to=1,length.out=21)
```

Para cada entrada σ2 de SIG2 y cada entrada de RHO:

  - Generar una muestra de tamaño N = 500 de una distribución bivariada normal $Z =(X,Y)$ donde $X \sim N(0,1)$ y $Y \sim N(0,\sigma^2)$ y el coeficientede correlación de X y Y es $\rho$. Z es una matriz de dimensiones 500 × 2.
  - Crear una matriz de 500 × 2, llámenlo EXPZ, con las exponenciales de las entradas de Z. ¿Qué distribución tienen estas variables transformadas?
  - Calculen el coeficiente de correlación, \hat{p} de las columnas de EXPZ. Grafiquen los puntos $(\sigma^2, \hat{ρ})$ y comenten sobre lo que obtuvieron.

La siguiente función permite generar una muestra aleatoria de tamaño n de una variable aleatoria normal multivariada con vector de medias $\mu$ y matriz de covarianzas $\Sigma$:
```{r}
rnorm_multivariate <- function(n,mu,Sigma){
  m <- length(mu)
  
  eig <- eigen(Sigma)
  lambda <- eig$values; 
  V <- eig$vectors
  
  Q <- V %*% diag(sqrt(lambda)) %*% t(V)
  
  Z <- matrix(rnorm(n*m),nrow=n, ncol=m)
  X <- Z %*% Q + matrix(mu,n,m,byrow=T)
  
  return (X)
}
```

Haciendo la simulación
```{r, warning=FALSE}
normales=list(NULL)
EXPZ = list(NULL)
i<-1
sigmas <- rep(0,2100)
rho_gorros <- rep(0,2100)
rhos <- rep(0,2100)

for (r in rho){
  for (s in sig2){
    
    Sigma = matrix(c(1,sqrt(s)*r,sqrt(s)*r,s),ncol=2)
    normales[[i]] <- rnorm_multivariate(5000, c(0,0), Sigma)
    EXPZ[[i]] <- exp(normales[[i]])
    
    sigmas[i] <- s
    rho_gorros[i] <- cor(EXPZ[[i]])[1,2]
    rhos[i] <- r
    
    i = i+1
  }
}
```
EXPZ se obtiene tras aplicar la función exponencial a una variable aleatoria distribuida normal de forma que EXPZ se distribuye lognormal.

Graficando:

```{r}
par(mfrow=c(1,2))
plot(sigmas,rhos)
plot(sigmas,rho_gorros)
```

La gráfica del lado izquierda está formada por los puntos $(\sigma^2, \rho)$ que fueron utilizados para generar las normales, la gráfica del lado derecho está formada por puntos de la forma $(\sigma^2, \hat{\rho})$ donde $\hat{\rho}$ es la correlación entre dos variables lognormales obtenidas a partir de las siguientes normales $N(0,1)$ y $N(0,\sigma^2)$.

Notamos que la correlación cambió sustancialmente.